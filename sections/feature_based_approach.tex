% !TeX root = ../report.tex

\section{Feature based approach}\label{sec:feature}

For the feature based approach, a feature extraction is done with regards to the term frequency - inverse document frequency. This has been the golden standard for feature extraction, and ensures that the features extracted have the highest descriptive effect with regards to the tweets in which the feature occurs versus the tweets in which the feature does not. These extracted features are then used for the training of one of two different models, depending on the subtask at hand.\\
Both models build on the random forest learning method since its properties support regression as well as multi-label classification. \\
Random Forest is an extended learning method that works as an ensemble of decision trees. In the ensemble, an input vector is sent down each tree in the forest and then the result can be either an average or a weighted average, in the case of regression, or the majority vote, in the case of classification.\\

\subsection{Custom features} \label{sec:customfeat}
Besides the Tf-idf feature extraction method, the model uses a custom feature extraction function. This function has different flags, corresponding to different features that could be of interest in these particular tweets. \\
The different custom features concern themselves with different textual points-of-interest, e.g. whether or not a hashtag is present or if the spelling error of the whole tweet is above some threshold. All of these custom features are boolean values in the sense that they are either present or not. The features are:\\
\begin{itemize}
\item Exclamation: check whether or not an exclamation mark is present in the tweet.
\item Hashtag: check whether or not a hashtag is present in the tweet.
\item Spelling: check whether or not a specified percentage of the tweet is mispelled.
\item Negative emoji: check whether or not an emoji from a list of negative emojis is present in the tweet.
\item Positive emoji: check whether or not an emoji from a list of positive emojis is present in the tweet.
\item Emoji: check whether or not an emoji is present in the tweet.
\end{itemize}
These features are then appended to the feature matrix returned by the Tf-idf extraction function, so that they are taken into consideration when training the different models. \\
Custom features can be based on linguistic and contextual intuition as well as a higher degree of linguistic analysis, as opposed to the deep learning features which will be trained with a more mathematically and statistical paradigm in mind.

\subsection{Model overview}
Both the models share the same feature extraction method and the actual models were implemented using libraries which allows for a very high level approach. This acted as an introduction to the subtasks and which of these would be interesting to focus on. Furthermore, the feature based model acted as a baseline system which would work as a stepstone for the deep learning models used later in the process. In the final version of the code, two feature based models were used:\\
\begin{itemize}
 \item Random forest classifier
 \item Random forest regressor
\end{itemize}
Since the regression task is done on four differing emotions, a regression model has to be trained for each emotion. Therefore the overall regression model actually consists of four random forest regressors, one for each emotion. Conversely, the classifier only needs one model since the classification is a multi-label classification instance and there only exists one, combined dataset.

\subsection{Hyperparameter testing}
\subsubsection{Regression, task 1} \label{sec:regfeat}
Figure \ref{fig:max_f_pearson} is a plot of the Pearson score with regards to the amount of max features used in the final feature based model to solve task 1. This model used all six custom features. Furthermore, an n-gram range of 1 to 5 was used in the model.
\begin{figure}[H]
    \centering
        \includegraphics[width=\textwidth]{pictures/max_f_pearson.png}
        \caption{Pearson score as a function of max-features from 500-30000 with n-gram range 1-5 and all the custom features on}
        \label{fig:max_f_pearson}
\end{figure}
It is evident from figure \ref{fig:max_f_pearson} that there is no clear-cut correlation between the max features and the Pearson score. The tests were run with up to 30000 max features.\\
\\
The use of n-grams in tweets was also complicated. Since the tweets are so dense and diverse, larger n-grams have very little chance of reappearing in other tweets, and as such there was very little difference in the n-gram ranges used when the max features were kept in place. The results of testing this is shown in table \ref{tab:ngram}.\\
\begin{table}[H]
\centering
\begin{tabular}{c|c|c|c|c|c}
N-gram range & \text{Anger} & \text{Fear} & \text{Joy} & \text{Sadness} & \textbf{Avg.}\\ \hline
\text{1-2} & 0.407 & 0.525 & 0.319 & 0.411 & 0.415 \\ \hline
\text{1-3} & 0.406 & 0.507 & 0.351 & 0.405 & 0.417 \\ \hline
\text{1-4} & 0.391 & 0.536 & 0.353 & 0.417 & \textbf{0.424} \\
\hline
\text{1-5} & 0.405 & 0.512 & 0.352 & 0.427 & \textbf{0.424} \\ \hline
\text{1-6} & 0.378 & 0.497 & 0.354 & 0.406 & 0.409 \\ \hline
\text{1-7} & 0.402 & 0.515 & 0.371 & 0.403 & 0.423 \\ \hline
\text{1-8} & 0.423 & 0.487 & 0.333 & 0.421 & 0.416 \\
\end{tabular}
\caption{Pearson scores with differing n-gram ranges, no custom features used, 1000 max features}
\label{tab:ngram}
\end{table}
The Pearson score as a result of n-gram range is hard to deduce and when looking at the n-grams produced with the larger ranges, only few of them were utilizing the maximum length allowed, most were uni- or bigram size.\\
If the n-gram ranges were forced to be 2 or higher, the Pearson score would drop off dramatically, again indicating a tendency towards unigrams and their predictive ability. This is shown in table \ref{tab:ngramspecial}.\\
\begin{table}[H]
\centering
\begin{tabular}{c|c|c|c|c|c}
N-gram range & \text{Anger} & \text{Fear} & \text{Joy} & \text{Sadness} & \textbf{Avg.} \\ \hline
\text{1-2} & 0.407 & 0.525 & 0.319 & 0.411 & \textbf{0.415} \\ \hline
\text{2-3} & 0.122 & 0.21 & 0.236 & 0.207 & 0.194 \\ \hline
\text{3-4} & -0.037 & 0.0 & 0.087 & 0.012 & 0.015 \\
\end{tabular}
\caption{Pearson scores with forced minimum n-gram range, no custom features, 1000 max features}
\label{tab:ngramspecial}
\end{table}
This tendency could be explained with the relatively small amount of data, the different tweeters and the difference in the words used in the tweets. \\
\\
Testing the custom feature and their significance, both with regards to the result, but also their interplay, is challenging. Exhausting all possible combinations of custom feature set-ups would result in $6+15+20+15+6+1 = 63$ different combinations of custom features used, and this is not taking into account any features that might influence one of the four models trained each run, since a new model is trained for each regression emotion. Therefore, the Pearson score as a result of a single custom feature used is shown in table \ref{tab:custom} and the importance of the custom features for each model/emotion combination trained is shown in table \ref{tab:customimportance}.
\begin{table}[H]
\centering
\begin{tabular}{c|c|c|c|c|c}
Custom feature & \text{Anger} & \text{Fear} & \text{Joy} & \text{Sadness} & \textbf{Avg.} \\ \hline
\text{Hashtag} & 0.407 & 0.483 & 0.457 & 0.408 & \textbf{0.439} \\ \hline
\text{Exclam} & 0.398 & 0.504 & 0.357 & 0.427 & \textbf{0.421} \\ \hline
\text{Spelling} & 0.406 & 0.506 & 0.356 & 0.422 & \textbf{0.422} \\ \hline
\text{Positive emoji} & 0.4 & 0.506 & 0.346 & 0.434 & \textbf{0.421} \\ \hline
\text{Negative emoji} & 0.411 & 0.518 & 0.354 & 0.438 & \textbf{0.430} \\ \hline
\text{Emoji} & 0.401 & 0.503 & 0.365 & 0.397 & \textbf{0.417} \\
\end{tabular}
\caption{Pearson scores with different custom features used. All models used 1000 max features and n-gram range 1-5.}
\label{tab:custom}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{c|c|c|c|c}
Custom feature & Anger & Fear & Joy & Sadness \\ \hline
\text{Hashtag} & 1000 & 987 & 1005 & 989 \\ \hline
\text{Exclam} & 974 & 997 & 1004 & 995\\ \hline
\text{Spelling} & 65 & 229 & 352 & 426\\ \hline
\text{Positive emoji} & 944 & 969 & 989 & 990\\ \hline
\text{Negative emoji} & 917 & 803 & 995 & 951\\ \hline
\text{Emoji} & 962 & 983 & 1000 & 993
\end{tabular}
\caption{Custom feature importance as extracted from each model with 1000 max features and n-gram range 1-5.}
\label{tab:customimportance}
\end{table}
The importance shown in table \ref{tab:customimportance} has no direct correlation with how well a custom feature might be to predict new data, only how much influence it has on the train data is had been applied to. This is evident in the fact that hashtag has an overall lower importance than spelling, but when running the model with the same set-up, with the hashtag or spelling custom features on, the spelling model gets a worse result than the hashtag model.

\subsubsection{Classification, task 5}
Figure \ref{fig:max_f_accuracy} is a plot of the accuracy with regards to the amount of max features used. This graph is equivalent to the one presented in section \ref{sec:regfeat}, just for the classification model. 
\begin{figure}[H]
    \centering
        \includegraphics[width=\textwidth]{pictures/max_f_accuracy.png}
        \caption{Accuracy as a function of max-features from 500-30000 with n-gram range 1-5 and all the custom features on}
        \label{fig:max_f_accuracy}
\end{figure}
With regards to the more subtle hyperparameters that the model relies on, n-gram range and custom features, the results of the classification model reflect the results of the regression model, i.e., including all custom features improves the score and the best n-gram range for the classification is also 1-5. 

\subsection{Results and data} \label{sec:featscores}
The final models used 1000 max features, all six custom features, mentioned in section \ref{sec:customfeat}, and an n-gram range of 1 to 5. The sanity check results can be seen in table \ref{tab:featsanityreg} and \ref{tab:featsanityclass}.

\begin{table}[H]
\centering
\begin{tabular}{c|c|c|c|c}
\text{Anger} & \text{Fear} & \text{Joy} & \text{Sadness} & \text{Avg.} \\ \hline
0.959 & 0.954 & 0.951 & 0.955 & 0.955 \\
\end{tabular}
\caption{Sanity check Pearson scores for regression}
\label{tab:featsanityreg}
\end{table}

\begin{table}[H]
\centering
\resizebox{\columnwidth}{!}{\begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c|c}
\multicolumn{12}{c}{\textbf{F-micro}} & \textbf{Global accuracy}\\ \hline
Anger & Anticipation & Disgust & Fear & Joy & Love & Optimism & Pessimism & Sadness & Surprise & Trust & Neutral & \\ \cline{1-12}
0.985 & 0.946 & 0.98 & 0.975 & 0.986 & 0.943 & 0.972 & 0.941 & 0.977 & 0.926 & 0.915 & 0.767 & 0.952 \\
\end{tabular}}
\caption{Sanity check Pearson scores for classification}
\label{tab:featsanityclass}
\end{table}
F-micro is the F-score calculated on a per-flag basis, as specified in the task outline (although with the added "neutral" emotion)\footnote{All the official evaluation metric are shown on \href{https://competitions.codalab.org/competitions/17751\#learn\_the\_details\-evaluation}{https://competitions.codalab.org/competitions/17751\#learn\_the\_details\-evaluation}.}. F-score and how it is used in the task is discussed in section \ref{sec:lossdiscussion}.\\
In table \ref{tab:featdevreg} and \ref{tab:featdevclass} the scores of the final model on the development data is shown.

\begin{table}[H]
\centering
\begin{tabular}{c|c|c|c|c}
\text{Anger} & \text{Fear} & \text{Joy} & \text{Sadness} & \text{Avg.} \\ \hline
0.415 & 0.475 & 0.429 & 0.472 & 0.448 \\
\end{tabular}
\caption{Regression scores on development data}
\label{tab:featdevreg}
\end{table}

\begin{table}[H]
\centering
\resizebox{\columnwidth}{!}{\begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c|c}
\multicolumn{12}{c}{\textbf{F-micro}} & \textbf{Global accuracy}\\ \hline
Anger & Anticipation & Disgust & Fear & Joy & Love & Optimism & Pessimism & Sadness & Surprise & Trust & Neutral & \\ \cline{1-12}
0.569 & 0.099 & 0.577 & 0.58 & 0.707 & 0.419 & 0.53 & 0.178 & 0.469 & 0.143 & 0.043 & 0.056 & 0.401 \\
\end{tabular}}
\caption{Classification scores on development data}
\label{tab:featdevclass}
\end{table}
