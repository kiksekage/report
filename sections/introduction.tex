% !TeX root = ../report.tex
\section{Introduction}
Humans communicate via natural language, but it is not only the message that is communicated, it is also the sentiment and intensity of that sentiment. Intensity of sentiment in sentences and words are borderline subjective and therefore difficult to classify in general. Therefore it is interesting to see if it is possible to build a model or program that can do that automatically. \\
To do this we use Natural Language Processing (NLP), and in this field detecting emotion or sentiment in text can be used for analysing stance towards political statements or online consumer reviews of products. \\
Twitter is a great service for detecting these sentiments, since it is user-written and often emotionally fuelled(spelling?).
\subsection{Task}
The task to be solved is the SemEval-2018 Task 1: Affect in Tweets, and can be found on \hyperref[https://competitions.codalab.org/competitions/17333]{https://competitions.codalab.org/competitions/17333}. The task is split into five subtasks:\\
\begin{enumerate}
\item EI-reg (Given a tweet and an emotion E, determine the  intensity of E that best represents the mental state of the tweeter—a real-valued score between 0 (least E) and 1 (most E).)
\item EI-oc (Given a tweet and an emotion E, classify the tweet into one of four ordinal classes of intensity of E that best represents the mental state of the tweeter.)
\item V-reg (Given a tweet, determine the intensity of sentiment or valence (V) that best represents the mental state of the tweeter—a real-valued score between 0 (most negative) and 1 (most positive).)
\item V-oc (Given a tweet, classify it into one of seven ordinal classes, corresponding to various levels of positive and negative sentiment intensity, that best represents the mental state of the tweeter.)
\item E-c (Given a tweet, classify it as 'neutral or no emotion' or as one, or more, of eleven given emotions that best represent the mental state of the tweeter.)
\end{enumerate}
 
For all of these subtasks, three language subsubtasks are present, for english, spanish and arabic.\\ 
\subsection{Models}
To best solve these subtasks we use different models to compare and analyse which are better for each subtask. Furthermore we try 2 different approaches to solve the tasks. One approach is the feature based approach which builds on the bag-of-words model (En reference måske?), which takes into account the individual words but not the context in which the words are placed in the sentence. The other approach is the Deep Learning(igen reference måske?) way, in which we implement a variation of a Recurrent Neural Network (RNN), called a gated recurrent unit.